# -*- coding: utf-8 -*-
"""Deployment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VC3sSAdatKafUTFysx1P-J4aXCrxAZo6
"""
import pandas as pd
from faker import Faker
import random
import numpy as np

# Initialize Faker
fake = Faker('en_IN')
Faker.seed(0)

# Set number of rows
num_rows = 1500

"""###This code generates a synthetic dataset of customer profiles and financial transactions, useful for testing models in finance or fraud detection. Each entry includes:


*   Customer Details: ID, age, gender, address, profession, income, and KYC status.
*   Bank Account Info: Account number, bank name, type, and daily transaction limit.
*   Transaction Details: Transaction date, number, source and destination accounts, amount, type (credit/debit), currency, location, and a flag indicating if it’s suspicious.




"""

# Generate dataset
data = []
for _ in range(num_rows):
    customer_id = fake.uuid4()
    dob = fake.date_of_birth(minimum_age=18, maximum_age=90)
    age = fake.random_int(min=18, max=90)
    gender = random.choice(['Male', 'Female'])
    relationship_status = random.choice(['Single', 'Married', 'Divorced', 'Widowed'])
    address = fake.address()
    tax_resident_country = 'India'
    profession = fake.job()
    income = round(fake.random_int(min=100000, max=1000000), 2)
    kyc = random.choice(['Verified', 'Pending', 'Rejected'])

    account_number = fake.iban()
    bank = fake.company()
    account_type = random.choice(['Savings', 'Current', 'Fixed Deposit'])
    daily_limit = round(fake.random_int(min=50000, max=500000), 2)

    transaction_date = fake.date_this_year()
    transaction_number = fake.uuid4()
    source_account = fake.iban()
    destination_account = fake.iban()
    amount = round(fake.random_int(min=500, max=100000), 2)
    transaction_type = random.choice(['Credit', 'Debit'])
    currency = 'INR'
    transaction_location = fake.city()
    suspicious_flag = random.choice(['Yes', 'No'])

    country = 'India'
    city = fake.city()

    # Append row data as dictionary
    data.append({
        "Customer ID": customer_id,
        "DOB": dob,
        "Age": age,
        "Gender": gender,
        "Relationship Status": relationship_status,
        "Address": address,
        "Tax Resident Country": tax_resident_country,
        "Profession": profession,
        "Income": income,
        "KYC": kyc,
        "Account Number": account_number,
        "ID": customer_id,
        "Bank": bank,
        "Account Type": account_type,
        "Daily Limit": daily_limit,
        "Transaction Date": transaction_date,
        "Transaction Number": transaction_number,
        "Source Account": source_account,
        "Destination Account": destination_account,
        "Amount": amount,
        "Transaction Type": transaction_type,
        "Currency": currency,
        "Transaction Location": transaction_location,
        "Suspicious Flag": suspicious_flag,
        "Country": country,
        "City": city
    })

# Create DataFrame
df = pd.DataFrame(data)

"""####To save the synthetic data into csv file"""

# Save to CSV
file_path = 'Indian_Banking_Dataset.csv'
df.to_csv(file_path, index=False)

print(f"Data generated and saved to {file_path}")

"""####Reading the synthetic data file"""

DATA = 'Indian_Banking_Dataset.csv'

df = pd.read_csv(DATA)

df.head()

df.shape

df.info()

df.describe()

"""####Infrences of dataset
*   Age: Average age is 53, with a range from 18 to 90, showing a mature and diverse customer base.
*   Income: Average income is ₹552,710, with a wide range from ₹102,696 to ₹998,576, indicating a mix of low to high-income customers.
*   Daily Limit: Average daily transaction limit is ₹269,189, with limits between ₹51,930 and ₹496,340.
*   Transaction Amount: Average transaction amount is ₹50,722, with values ranging from ₹554 to ₹99,099, indicating varied transaction sizes.




"""

#Missing Values
missing_values = df.isnull().sum()
print("Columns with missing values:")
print(missing_values)

#Null Values
null_values = df.isnull().sum()
print("Columns with null values:")
print(null_values)

df.dtypes

df.columns

import pandas as pd

# Convert columns to datetime format
df['DOB'] = pd.to_datetime(df['DOB'], errors='coerce')
df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')

# Verify the data types
print(df.dtypes)

#Columns to drop
columnstodrop= ["Address", "Tax Resident Country", "Customer ID", "Country"]
df.drop(columns=columnstodrop, inplace=True)

df.dtypes

from sklearn.preprocessing import LabelEncoder
#Encode Variables
CategoricalColumns=["Gender", "Relationship Status", "Transaction Type", "KYC", "Account Type", "Suspicious Flag"]
label_encoders = {}

for column in CategoricalColumns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

df.head()

import matplotlib.pyplot as plt
import seaborn as sns

#Distribution Plot
plt.figure(figsize=(10, 6))
sns.histplot(df, x='Amount', hue='Suspicious Flag', bins=30, kde=True)
plt.title('Distribution of Transaction Amounts by Suspicious Flag')
plt.xlabel('Transaction Amount')
plt.ylabel('Frequency')
plt.legend(['Non-Suspicious', 'Suspicious'])
st.pyplot(plt)
plt.clf()

"""**INFERENCES** **OF** **THIS** **GRAPH** : This graph shows the distribution of transaction amounts, categorized as "Suspicious" (blue) or "Non-Suspicious" (orange). Each bar represents the frequency of transactions within specific amount ranges, with a gray background indicating the overall total. The KDE curves suggest that "Non-Suspicious" transactions have a relatively consistent distribution across the range, with peaks around 20,000, 50,000, and 80,000. "Suspicious" transactions also appear consistently across amounts but show distinct peaks at different points, notably around 40,000 and 90,000. This pattern suggests that certain transaction amounts may be more prone to being flagged as suspicious, possibly due to thresholds or triggers used in monitoring systems."""

selected_columns = ['Account Type', 'KYC', 'Transaction Type']

for column in selected_columns:
    plt.figure(figsize=(10, 6))
    sns.histplot(df, x=column, hue='Suspicious Flag', bins=30, kde=True)
    plt.title(f'Distribution of {column} by Suspicious Flag')
    plt.xlabel(f'Distribution of {column}')
    plt.ylabel('Frequency')
    plt.legend(['Non-Suspicious', 'Suspicious'])
    st.pyplot(plt)
    plt.clf()

"""# INFERENCES OF THE FOLLOWING GRAPHS:
***1***) This graph shows the frequency distribution of different account types (coded as 0, 1, and 2) and their classification as "Suspicious" (blue) or "Non-Suspicious" (orange). Most accounts across all types are non-suspicious, indicated by large gray bars with small colored segments at the top representing the flagged accounts. Account type "0" has the highest frequency of "Non-Suspicious" accounts, while account type "1" has a relatively higher proportion of "Suspicious" flags compared to the other types. The KDE curves for both categories are mostly flat, suggesting a consistent distribution without strong trends toward any specific account type being flagged, though account type "1" appears slightly more prone to suspicion.

***2***)This graph shows the distribution of KYC status across "Suspicious" and "Non-Suspicious" flags:

1. The majority of "KYC" values are clustered at discrete points (0, 1, and 2).
2. There’s a higher frequency of individuals with "KYC" values at these points, with a significant number marked as "Suspicious" or "Non-Suspicious."
3. Kernel density estimates (the smooth lines) show similar patterns for both "Suspicious" and "Non-Suspicious" categories, with slight variations in density.

***3***)This graph displays the distribution of transaction types (coded as 0 and 1) by whether they are flagged as "Suspicious" (blue) or "Non-Suspicious" (orange). Most transactions in both types are non-suspicious, as shown by the large gray bars, with a small proportion flagged as suspicious at the top of each bar. Transaction type "0" has a small segment of "Non-Suspicious" flags, while transaction type "1" has a slightly higher proportion of "Suspicious" flags. The KDE curves for both "Suspicious" and "Non-Suspicious" flags are relatively flat, indicating no strong density trend in either direction. Overall, type "1" transactions appear marginally more prone to being flagged as suspicious compared to type "0."
"""

#  Class Balance
plt.figure(figsize=(6,4))
sns.countplot(x='Suspicious Flag', data=df)
plt.title('Distribution of Suspicious Flag')
st.pyplot(plt)
plt.clf()

# Suspicious vs Non-Suspicious Proportions
proportions = df['Suspicious Flag'].value_counts(normalize=True)
print(f"Proportions of Suspicious vs Non-Suspicious: \n{proportions}")

#  Bar Plots for Categorical Features
categorical_features = ["Gender", "Relationship Status", "Transaction Type", "KYC", "Account Type", "Suspicious Flag"]
for feature in categorical_features:
    plt.figure(figsize=(6,4))
    sns.countplot(x=feature, data=df, hue='Suspicious Flag')
    plt.title(f'{feature} by Suspicious Flag')
    st.pyplot(plt)
    plt.clf()

#  Daily Limit by Transaction Type and Suspicious Flag
plt.figure(figsize=(6,4))
sns.boxplot(x='Transaction Type', y='Daily Limit', hue='Suspicious Flag', data=df)
plt.title('Daily Limit by Transaction Type and Suspicious Flag')
st.pyplot(plt)
plt.clf()

#  Check if Cities have higher occurrences of suspicious transactions
plt.figure(figsize=(6,4))
sns.countplot(x='City', data=df, hue='Suspicious Flag')
plt.title('Suspicious Transactions by City')
plt.xticks(rotation=90)
st.pyplot(plt)
plt.clf()
